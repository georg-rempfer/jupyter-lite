{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Description\n\nCalculates the Bayesian credibility for the hypothesis that the event occurrence rate during a test B is higher than that during a test A, given the test duration and number of observed events for both test run A and B.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Parameters",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test_duration_A = 100\nn_events_A = 20\n\ntest_duration_B = 10\nn_events_B = 1\n\nround_to_digits = 4\n\nassert isinstance(test_duration_A, (int, float)) and test_duration_A > 0\nassert isinstance(test_duration_B, (int, float)) and test_duration_B > 0\nassert isinstance(n_events_A, int) and n_events_A >= 0\nassert isinstance(n_events_B, int) and n_events_B >= 0\nassert isinstance(round_to_digits, int) and round_to_digits >= 1",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "# Evaluation",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport mpmath as mp\nimport numpy as np\nfrom scipy import integrate\n\nmp.mp.dps = 50 #use 50 decimal digits precision in mpmath calculations\n\n#posterior is unnormalized to save calculation time, remember to normalize result when needed\ndef posterior_prob_poisson_r(r_event, test_duration, n_events, prior):\n    return mp.power(mp.mpf(r_event*test_duration), n_events) / mp.fac(n_events) * mp.exp(-r_event*test_duration) * prior(r_event, test_duration)\n\nposterior_prob_poisson_r_vectorized = np.vectorize(posterior_prob_poisson_r)\n\ndef posterior_pairs(r_A, test_duration_A, n_events_A, prior_A, r_B, test_duration_B, n_events_B, prior_B):\n    return posterior_prob_poisson_r_vectorized(r_A, test_duration_A, n_events_A, prior=prior_A) * posterior_prob_poisson_r_vectorized(r_B, test_duration_B, n_events_B, prior=prior_B)\n\n#split the integral into constant and non-constant parts and prescale so numerical integration does not fail due to sharp peak for large test_duration\ndef integrate_posterior_prob_poisson_r(test_duration, n_events, prior, bounds):\n    mean = (n_events+1) / test_duration\n    std_dev = (n_events+1)**0.5 / test_duration\n    prescale = 1/posterior_prob_poisson_r(mean, test_duration, n_events, prior)\n    prior_prescaled = lambda r, duration: prior(r, duration) * prescale\n    \n    result = 0\n    if bounds[0] < mean-3*std_dev:\n        result += integrate.quad(posterior_prob_poisson_r, max(0, bounds[0]), min(mean-3*std_dev, bounds[1]), args=(test_duration, n_events, prior_prescaled))[0]\n    if bounds[0] < mean and bounds[1] >= mean-3*std_dev:\n        result += integrate.quad(posterior_prob_poisson_r, max(mean-3*std_dev, bounds[0]), min(mean, bounds[1]), args=(test_duration, n_events, prior_prescaled))[0]\n    if bounds[0] < mean+3*std_dev and bounds[1] >= mean:\n        result += integrate.quad(posterior_prob_poisson_r, max(mean, bounds[0]), min(mean+3*std_dev, bounds[1]), args=(test_duration, n_events, prior_prescaled))[0]\n    if bounds[1] >= mean+3*std_dev:\n        result += integrate.quad(posterior_prob_poisson_r, max(mean+3*std_dev, bounds[0]), bounds[1], args=(test_duration, n_events, prior_prescaled))[0]\n        \n    return result / prescale\n    \n#split the integral into constant and non-constant parts and prescale so numerical integration does not fail due to sharp peak for large n_trial\ndef integrate_lower_triangle(test_duration_A, n_events_A, prior_A, test_duration_B, n_events_B, prior_B):\n    mean_A = (n_events_A+1) / test_duration_A\n    std_dev_A = (n_events_A+1)**0.5 / test_duration_A\n    prescale_A = 1/posterior_prob_poisson_r(mean_A, test_duration_A, n_events_A, prior_A)\n    prior_prescaled_A = lambda r, duration: prior_A(r, duration) * prescale_A\n    \n    mean_B = (n_events_B+1) / test_duration_B\n    std_dev_B = (n_events_B+1)**0.5 / test_duration_B\n    prescale_B = 1/posterior_prob_poisson_r(mean_B, test_duration_B, n_events_B, prior_B)\n    prior_prescaled_B = lambda r, duration: prior_B(r, duration) * prescale_B\n\n    bounds = [0, np.inf]\n\n    f = lambda x: posterior_prob_poisson_r(x, test_duration_A, n_events_A, prior_prescaled_A) * integrate_posterior_prob_poisson_r(test_duration_B, n_events_B, prior_prescaled_B, [0, x])\n    \n    result = 0\n    if bounds[0] < mean_A-3*std_dev_A:\n        result += integrate.quad(f, max(0, bounds[0]), min(mean_A-3*std_dev_A, bounds[1]))[0]\n    if bounds[0] < mean_A and bounds[1] >= mean_A-3*std_dev_A:\n        result += integrate.quad(f, max(mean_A-3*std_dev_A, bounds[0]), min(mean_A, bounds[1]))[0]\n    if bounds[0] < mean_A+3*std_dev_A and bounds[1] >= mean_A:\n        result += integrate.quad(f, max(mean_A, bounds[0]), min(mean_A+3*std_dev_A, bounds[1]))[0]\n    if bounds[1] >= mean_A+3*std_dev_A:\n        result += integrate.quad(f, max(mean_A+3*std_dev_A, bounds[0]), bounds[1])[0]\n        \n    return result / prescale_A / prescale_B\n\nr_plotmax_A = (n_events_A+1)/test_duration_A + 3*(n_events_A+1)**0.5/test_duration_A #mean+5*std_dev\nr_plotmax_B = (n_events_B+1)/test_duration_B + 3*(n_events_B+1)**0.5/test_duration_B #mean+5*std_dev\nr_maxplot = max(r_plotmax_A, r_plotmax_B)\n\nr_A = np.linspace(0, r_maxplot, 101)\nr_B = np.linspace(0, r_maxplot, 101)\n\nprior_A = lambda r, duration: 1\nprior_B = lambda r, duration: 1\n\nnorm_A = integrate_posterior_prob_poisson_r(test_duration_A, n_events_A, prior_A, [0, np.inf])\nnorm_B = integrate_posterior_prob_poisson_r(test_duration_B, n_events_B, prior_B, [0, np.inf])\n\nX, Y = np.meshgrid(r_A, r_B)\nposterior_probs = posterior_pairs(X, test_duration_A, n_events_A, prior_A, Y, test_duration_B, n_events_B, prior_B) / (norm_A * norm_B)\n\nP_rA_larger_rB = integrate_lower_triangle(test_duration_A, n_events_A, prior_A, test_duration_B, n_events_B, prior_B) / (norm_A * norm_B)\nP_rB_larger_rA = integrate_lower_triangle(test_duration_B, n_events_B, prior_B, test_duration_A, n_events_A, prior_A) / (norm_A * norm_B)\nP_rA_larger_rB_rounded = mp.nstr(mp.mpf(P_rA_larger_rB), round_to_digits)\nP_rB_larger_rA_rounded = mp.nstr(mp.mpf(P_rB_larger_rA), round_to_digits)\nP_sum = P_rB_larger_rA + P_rA_larger_rB\nnumerical_error_estimate = abs(P_sum - mp.mpf(1))\n\nplt.contourf(X, Y, posterior_probs, cmap='Blues')\nplt.axline([0,0], [r_maxplot,r_maxplot], color='red', alpha=0.3)\n\nplt.gca().set_title('Poisson experiment {} events / duration {} (A) vs. {} events / duration {} (B)\\nBayesian pair posterior with uniform prior\\nOrder of numerical error: {}%'.format(n_events_A,\n                    test_duration_A, n_events_B, test_duration_B, mp.nstr(numerical_error_estimate * 100, round_to_digits)))\nplt.gca().set_xlabel('event occurrence rate A')\nplt.gca().set_ylabel('event occurence rate B')\nplt.gca().tick_params(axis='x', which='minor', bottom=True)\nplt.gca().minorticks_on()\nplt.grid(which='major')\nplt.grid(which='minor', alpha=0.3);\nplt.gca().set_aspect('equal')\n\nplt.text(r_maxplot*0.3, r_maxplot*0.7, '$P(r_B > r_A)$\\n=${}$'.format(P_rB_larger_rA_rounded), horizontalalignment='center', verticalalignment='center', fontsize='xx-large', fontweight='bold', alpha=0.6)\nplt.text(r_maxplot*0.7, r_maxplot*0.3, '$P(r_A > r_B)$\\n=${}$'.format(P_rA_larger_rB_rounded), horizontalalignment='center', verticalalignment='center', fontsize='xx-large', fontweight='bold', alpha=0.6);",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
